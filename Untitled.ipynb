{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502ebd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "     ---------------------------------------- 8.2/8.2 MB 21.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "     ---------------------------------------- 330.3/330.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp39-none-win_amd64.whl (277 kB)\n",
      "     ---------------------------------------- 277.8/277.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (1.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.0-cp39-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 46.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "     ------------------------------------- 169.0/169.0 kB 10.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\desktop\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.2.0\n",
      "    Uninstalling fsspec-2022.2.0:\n",
      "      Successfully uninstalled fsspec-2022.2.0\n",
      "Successfully installed fsspec-2023.12.2 huggingface-hub-0.20.2 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5663f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "headlines_dataset = pd.read_json(\"Sarcasm_Headlines_Dataset.json\",lines=True)\n",
    "headlines_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c5bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# OH FUCK OH SHIT OH FUCK OH SHIT I CAN KNOCK THIS OUT IN A DAY CAN'T I?\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f6a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of true cases to total cases: 0.43895316185555433\n",
      " Original:  'ant-man and the wasp' trailer brings the fun after 'avengers: infinity war'\n",
      "Tokenized:  [\"'\", 'ant', '-', 'man', 'and', 'the', 'wasp', \"'\", 'trailer', 'brings', 'the', 'fun', 'after', \"'\", 'avengers', ':', 'infinity', 'war', \"'\"]\n",
      "Token IDs:  [1005, 14405, 1011, 2158, 1998, 1996, 19411, 1005, 9117, 7545, 1996, 4569, 2044, 1005, 14936, 1024, 15579, 2162, 1005]\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of true cases to total cases:\",headlines_dataset[headlines_dataset['is_sarcastic']==1].shape[0]/headlines_dataset.shape[0])\n",
    "# Given that the above proportion is approximately 50, I won't need to do much debiasing.\n",
    "import torch\n",
    "device = torch.device(\"cpu\") # torch not compiled with cuda, cba to fix\n",
    "\n",
    "# create our sentence and label lists\n",
    "headlines = headlines_dataset['headline']\n",
    "labels = headlines_dataset['is_sarcastic']\n",
    "\n",
    "# Check tokenizer works using check from L4 notebook\n",
    "print(' Original: ', headlines[222])\n",
    "print('Tokenized: ', tokenizer.tokenize(headlines[222]))\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(headlines[222])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4de6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding and special characters for formatting\n",
    "\n",
    "max_len = 0\n",
    "for headline in headlines:\n",
    "    tokenized = ['[CLS]',*tokenizer.tokenize(headline),'[SEP]']\n",
    "    max_len = max_len if len(tokenized)<=max_len else len(tokenized)\n",
    "\n",
    "    \n",
    "# do encoding\n",
    "\n",
    "encoded_inputs = []\n",
    "attention_masks = []\n",
    "\n",
    "for headline in headlines:\n",
    "    encoded = tokenizer.encode_plus(\n",
    "                headline,\n",
    "                add_special_tokens = ['[CLS]','[SEP]'],\n",
    "                max_length=max_len,\n",
    "                pad_to_max_length= True,\n",
    "                return_attention_mask = True,   \n",
    "                return_tensors = 'pt',\n",
    "            )\n",
    "    encoded_inputs.append(encoded['input_ids'])\n",
    "    attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "inputs = torch.cat(encoded_inputs,dim=0)\n",
    "attention_masks = torch.cat(attention_masks,dim=0)\n",
    "labels = torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c78a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,038 training samples\n",
      "2,671 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(inputs, attention_masks, labels)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train, test = random_split(dataset, [train_size,val_size])\n",
    "val, test = random_split(test, [int(0.5*len(test)),len(test)-int(0.5*len(test))])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9354c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train,  # The training samples.\n",
    "            sampler = RandomSampler(train), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "validation_dataloader = DataLoader(\n",
    "            val, # The validation samples.\n",
    "            sampler = SequentialSampler(val), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "            test,\n",
    "            sampler = SequentialSampler(test),\n",
    "            batch_size = batch_size\n",
    "        ) # Made a test dataset since none is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfdb0397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ecf9ebd8ae4292a6a58075a4ef8d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desktop\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\desktop\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\desktop\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "# TODO: use cuda access, reconfigure torch for cuda\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 0.00002) # TODO: Try SGD with annealing momentum.\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "# Epoch number by BERT Recommendations\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "220bdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    752.    Elapsed: 0:05:10.\n",
      "  Batch    80  of    752.    Elapsed: 0:10:26.\n",
      "  Batch   120  of    752.    Elapsed: 0:15:40.\n",
      "  Batch   160  of    752.    Elapsed: 0:20:51.\n",
      "  Batch   200  of    752.    Elapsed: 0:26:01.\n",
      "  Batch   240  of    752.    Elapsed: 0:31:11.\n",
      "  Batch   280  of    752.    Elapsed: 0:36:22.\n",
      "  Batch   320  of    752.    Elapsed: 0:41:33.\n",
      "  Batch   360  of    752.    Elapsed: 0:46:43.\n",
      "  Batch   400  of    752.    Elapsed: 0:51:54.\n",
      "  Batch   440  of    752.    Elapsed: 0:57:04.\n",
      "  Batch   480  of    752.    Elapsed: 1:02:15.\n",
      "  Batch   520  of    752.    Elapsed: 1:07:25.\n",
      "  Batch   560  of    752.    Elapsed: 1:12:34.\n",
      "  Batch   600  of    752.    Elapsed: 1:17:44.\n",
      "  Batch   640  of    752.    Elapsed: 1:22:54.\n",
      "  Batch   680  of    752.    Elapsed: 1:28:05.\n",
      "  Batch   720  of    752.    Elapsed: 1:33:16.\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epoch took: 1:37:19\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.41\n",
      "  Validation took: 0:01:38\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    752.    Elapsed: 0:05:11.\n",
      "  Batch    80  of    752.    Elapsed: 0:10:22.\n",
      "  Batch   120  of    752.    Elapsed: 0:15:34.\n",
      "  Batch   160  of    752.    Elapsed: 0:20:46.\n",
      "  Batch   200  of    752.    Elapsed: 0:25:57.\n",
      "  Batch   240  of    752.    Elapsed: 0:31:10.\n",
      "  Batch   280  of    752.    Elapsed: 0:36:20.\n",
      "  Batch   320  of    752.    Elapsed: 0:41:29.\n",
      "  Batch   360  of    752.    Elapsed: 0:46:40.\n",
      "  Batch   400  of    752.    Elapsed: 0:51:51.\n",
      "  Batch   440  of    752.    Elapsed: 0:57:01.\n",
      "  Batch   480  of    752.    Elapsed: 1:02:13.\n",
      "  Batch   520  of    752.    Elapsed: 1:07:30.\n",
      "  Batch   560  of    752.    Elapsed: 1:12:41.\n",
      "  Batch   600  of    752.    Elapsed: 1:17:52.\n",
      "  Batch   640  of    752.    Elapsed: 1:23:03.\n",
      "  Batch   680  of    752.    Elapsed: 1:28:13.\n",
      "  Batch   720  of    752.    Elapsed: 1:33:23.\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epoch took: 1:37:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.41\n",
      "  Validation took: 0:01:38\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    752.    Elapsed: 0:05:11.\n",
      "  Batch    80  of    752.    Elapsed: 0:10:21.\n",
      "  Batch   120  of    752.    Elapsed: 0:15:31.\n",
      "  Batch   160  of    752.    Elapsed: 0:20:41.\n",
      "  Batch   200  of    752.    Elapsed: 0:25:51.\n",
      "  Batch   240  of    752.    Elapsed: 0:31:01.\n",
      "  Batch   280  of    752.    Elapsed: 0:36:11.\n",
      "  Batch   320  of    752.    Elapsed: 0:41:22.\n",
      "  Batch   360  of    752.    Elapsed: 0:46:33.\n",
      "  Batch   400  of    752.    Elapsed: 0:51:44.\n",
      "  Batch   440  of    752.    Elapsed: 0:56:53.\n",
      "  Batch   480  of    752.    Elapsed: 1:02:04.\n",
      "  Batch   520  of    752.    Elapsed: 1:07:14.\n",
      "  Batch   560  of    752.    Elapsed: 1:12:25.\n",
      "  Batch   600  of    752.    Elapsed: 1:17:34.\n",
      "  Batch   640  of    752.    Elapsed: 1:22:44.\n",
      "  Batch   680  of    752.    Elapsed: 1:27:55.\n",
      "  Batch   720  of    752.    Elapsed: 1:33:06.\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epoch took: 1:37:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.41\n",
      "  Validation took: 0:01:38\n",
      "\n",
      "Training complete!\n",
      "Total training took 4:56:48 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "total_steps = batch_size*epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Using the training schedule from L4 notebook, may alter it slightly.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "seed_val = 1733\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "total_t0 = time.time() # for timekeeping\n",
    "\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # 0 the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which\n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,\n",
    "                       token_type_ids=None,\n",
    "                       attention_mask=b_input_mask,\n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            result = model(b_input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cb35642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metrics(pred,label):\n",
    "    acc_count = 0\n",
    "    tp_count = 0\n",
    "    pred_p = 0\n",
    "    p_count = 0\n",
    "    fn_count = 0\n",
    "    print(pred)\n",
    "    for i in range(len(label)):\n",
    "        if(label[i]==1):\n",
    "            p_count +=1\n",
    "        if(pred[i]==1):\n",
    "            pred_p +=1 \n",
    "        if(pred[i]==label[i]):\n",
    "            if(pred[i]==1):\n",
    "                acc_count += 1\n",
    "                tp_count += 1\n",
    "        elif(pred[i]==0):\n",
    "            fn_count += 1\n",
    "    recall = tp_count/p_count\n",
    "    prec = tp_count/pred_p\n",
    "    f1_score = (2*prec*recall)/(prec+recall)\n",
    "    return recall, prec, f1_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08577e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for test sentences...\n",
      "    DONE.\n",
      "[1 1 0 ... 1 0 0]\n",
      "Recall: 0.7993366500829188 | Precision: 0.8860294117647058 | F-score: 0.840453356582389\n"
     ]
    }
   ],
   "source": [
    "#L4 Notebook test set eval. Modified to run on the test split, won't be using the MCC metric as we have a much more balanced dataset.\n",
    "print('Predicting labels for test sentences...')\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "        result = model(b_input_ids,\n",
    "                     token_type_ids=None,\n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "  # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "# Since we have a binary classification problem, it's best to use traditional accuracy, F1-score, etc. for metrics\n",
    "\n",
    "# We'll use the above defined make metrics for this.\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "rec, prec, f1 = make_metrics(flat_predictions,flat_true_labels)\n",
    "\n",
    "print(f\"Recall: {rec} | Precision: {prec} | F-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bbf4467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(flat_true_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c7bcc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7136127  -2.4550376 ]\n",
      " [-1.9409786   2.3515515 ]\n",
      " [ 1.4942142  -2.1744328 ]\n",
      " [ 1.7109648  -2.4028144 ]\n",
      " [ 1.5528997  -2.3274906 ]\n",
      " [-1.4110042   1.1838276 ]\n",
      " [-2.1308155   2.2859468 ]\n",
      " [-1.9099523   2.3457198 ]\n",
      " [ 1.6587044  -2.441039  ]\n",
      " [ 1.5099427  -2.3406188 ]\n",
      " [ 1.5694662  -2.3771844 ]\n",
      " [ 1.618523   -2.345673  ]\n",
      " [-1.9388567   2.1904244 ]\n",
      " [ 1.737904   -2.4206095 ]\n",
      " [-0.9069953   0.22273593]\n",
      " [-1.9604734   2.203607  ]\n",
      " [ 1.5393292  -2.2266157 ]\n",
      " [ 1.5478286  -2.2208893 ]\n",
      " [ 1.7247337  -2.383864  ]\n",
      " [ 1.6730539  -2.3987594 ]\n",
      " [-1.8853599   1.9567157 ]\n",
      " [-1.5683261   1.0861459 ]\n",
      " [-1.7728957   1.8603891 ]\n",
      " [ 1.8481928  -2.5344734 ]\n",
      " [ 1.6420707  -2.493122  ]\n",
      " [ 1.8643018  -2.52133   ]\n",
      " [ 1.6651282  -2.461564  ]\n",
      " [ 1.2439026  -1.9205402 ]\n",
      " [ 1.5505097  -2.4101198 ]\n",
      " [ 0.7666192  -1.5124873 ]\n",
      " [-1.951837    2.340269  ]\n",
      " [-1.4433123   1.237414  ]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc09823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
